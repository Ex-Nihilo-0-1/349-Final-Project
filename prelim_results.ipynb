{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the Task\n",
    "\n",
    "Predict county level presidential election results based on historical economic data. Take 2024 as an example. The goal is to build a model that takes the economic data of 2021, 2022, 2023 of a county as input, and gives \"R\" or \"D\" as output.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results \n",
    "\n",
    "1. The specification of the neural network:\n",
    "\n",
    "\n",
    "\n",
    "        model = torch.nn.Sequential(\n",
    "                torch.nn.Linear(72, 256, bias = True),\n",
    "                torch.nn.LeakyReLU(),\n",
    "                torch.nn.Linear(256, 512),\n",
    "                torch.nn.LeakyReLU(),\n",
    "                torch.nn.Linear(512, 256),\n",
    "                torch.nn.LeakyReLU(),\n",
    "                torch.nn.Linear(256, 256),\n",
    "                torch.nn.LeakyReLU(),\n",
    "                torch.nn.Linear(256, 1),\n",
    "                torch.nn.Sigmoid(),\n",
    "    )  \n",
    "\n",
    "2. Hyperparameters:\n",
    "    \n",
    "        lr = 0.0025, epochs = 3000, training_accuracy_threshold(stops after) = 0.95, batchsize = len(training_set)\n",
    "\n",
    "3. Training Method: \n",
    "\n",
    "        optimizer = torch.optim.Adam(list(nn.parameters()), lr=lr)\n",
    "        dataLoader = torch.utils.data.DataLoader(training_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for d, l in dataLoader:\n",
    "    \n",
    "                y_pred = nn(d)\n",
    "                loss = loss_fn(y_pred, l)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                test_accuracy = training_accuracy(input_training_set, nn)\n",
    "                test_accuracy = np.round(test_accuracy,2)\n",
    "                valid_accuracy = training_accuracy(input_valid_set, nn)\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "Our training data so far consists of presidential election results and 24 economic indicators from 1969 up to 2008. We have yet to incoporate the same data from 2008 to 2024, which we already possess, into our training data. There are also a couple dozen other economic indicators we haven't used. Currently, at best, we have `0.96` training accuracy and `0.83` validation accuracy (see the training curves below drawn using TensorBoard). 90% is a priori a high level of performance, therefore it suffices as a baseline.There is also a model that takes similar data as input, which has 0.93 for \"overall accuracy\": https://scholar.smu.edu/cgi/viewcontent.cgi?article=1005&context=datasciencereview.  But `0.83` is not far below either baselines, even without accounting the fact that we haven't used all the data we have.\n",
    "\n",
    "Loss\n",
    "<div>\n",
    "    <img src=\"loss.png\" width=\"1000\"/>\n",
    "</div>\n",
    "\n",
    "Training Accuracy\n",
    "\n",
    "<div>\n",
    "    <img src=\"training.png\" width=\"1000\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "Validation Accuracy\n",
    "\n",
    "<div>\n",
    "    <img src=\"valid.png\" width=\"1000\"/>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis ##\n",
    "\n",
    "1. No major issue is with training method or the (hyper-)parameters of the model, as the loss and training accuracy asymptotically improves.\n",
    "\n",
    "\n",
    "2. What accounts for the current result being below the baseline of 0.9-0.93 could be because validation accuracy seems to go down after 1000 epochs, while training accuracy keeps going up after. This suggests overfitting. However, this could be improved by adding more data. This is reasonable because we have yet to incorporate another .csv file containing other economic indicators for all counties in the US into our training data, and currently all our data are up to 2008.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
